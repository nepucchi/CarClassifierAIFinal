# -*- coding: utf-8 -*-
"""V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UBcVspfYB-h8N_1zyd7l3Rcw58v258Cm

# Reverse Image Search in Automated Parking Systems
Notebook ini kami buat sebagai contoh dari penerapan Image Recognition berupa reverse image search. sebagai mock-up, algoritma akan menggunakan model pre-trained yang disediakan oleh tensorflow untuk mencari gambar yang sama dari dataset besar untuk mensimulasikan kasus nyata.

### Dataset
kami akan gunakan kombinasi dari 3 dataset untuk memastikan hasil yang didapatkan dari model kita akurat.
berikut terdapat link Google Drive untuk semua dataset yang digunakan:
https://drive.google.com/drive/folders/15i39V-ge1xba-cElbDh9gFg3rfYi_C3X?usp=share_link

### Prerequisites
"""

pip install --upgrade --no-cache-dir gdown

#import model yang akan digunakan
import os
import keras
from keras.preprocessing import image
from keras.applications.imagenet_utils import decode_predictions, preprocess_input
from keras.models import Model

"""###Importing our dataset"""

# !gdown  https://drive.google.com/uc?id=1EoizvEdoNyZwzsvSmMfly9TP57fREuL8
!gdown  https://drive.google.com/uc?id=1P3UyGO3Yj1Uh7SxHgLoPqIeLOVbM4spM
!gdown  https://drive.google.com/uc?id=1xiJybNsZhKnL-2NXi2F4VvtAnrXZZCuZ

# !tar -xzf 101_ObjectCategories.tar.gz
!tar -xzf epfl_gims08.tar.gz
!unzip frontview.zip

# !rm 101_ObjectCategories.tar.gz
!rm epfl_gims08.tar.gz
!ls

"""###Importing our Model
model yang akan kami gunakan berupa *VGG16* yang disediakan oleh package *keras*
model tersebut memiliki convulional layer sebanyak 13, dan karena itu dapat membuat ribuan kategori untuk menampung dataset yang kami import. model ini juga sudah pre-trained dengan lebih dari satu juta weight yang disediakan oleh imagenet.
"""

model = keras.applications.VGG16(weights='imagenet', include_top=True)

"""###Fitting Our Data
karena model yang kami gunakan hanya dapat memproses gambar dengan ukuran (224 x 224 x 3), maka kita akan membuat sebuah function untuk memproses gambar input kita menjadi ukuran yang dapat diproses oleh model kita.
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

def load_image(path):
  target = tf.keras.utils.load_img(path, target_size=model.input_shape[1:3])

  vector = tf.keras.utils.img_to_array(target)
  vector = np.expand_dims(vector, axis=0)
  vector = preprocess_input(vector)
  return target, vector

"""###Classifier Model
pada tahap ini, kita akan mengambil salah satu layer yang terdapat pada model **VGG16** yang kita gunakan, yaitu layer ```fc2```.
layer ini akan kita implementasikan menjadi sebuah copy dari model awal kita bersama dengan weight yang sudah ada menjadi sebuah model baru. model yang dibuat pada tahap ini bertugas untuk membuat klasifikasi untuk gambar yang ada pada input. sehingga jika klasifikasi yang muncul mirip, maka kita dapat menemukan pasangan gambar yang mirip dengan input.


"""

ClassifierModel = Model(inputs=model.input, outputs=model.get_layer("fc2").output)

"""###Data Preparations
setelah kita memiliki model yang akan kita gunakan, maka tahap selanjutnya adalah menemukan image apa saja yang akan kita gunakan untuk melatih AI kita.
"""

import time
import random
images_path = '/content/'
image_extensions = ['.jpg', '.png', '.jpeg']
max_num_images = 10000

#determining the size of our array recursively
images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(images_path) for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]

#storing the images into our array
if max_num_images < len(images):
    images = [images[i] for i in sorted(random.sample(range(len(images)), max_num_images))]


time.perf_counter()
start= 0

res = []
for i, image_path in enumerate(images):
    if i % 500 == 0:
        end= time.perf_counter()
        total = end-start;
        print("analyzing image %d out of %d. Time Elapsed: %4.4f seconds." % (i, len(images),total))
        start = time.perf_counter()
    img, x = load_image(image_path);
    feat = ClassifierModel.predict(x)[0]
    res.append(feat)

print('finished extracting results for %d images' % len(images))

"""###Compressing Results
setelah kita mendapatkan hasil kita yang disimpan pada array, kita akan melakukan satu tahap lagi sebelum komparasi akhir, yaitu kompresi. kita akan menggunakan prosedur Principal Component Analysis (PCA) untuk mengambil 300 komponen utama kita, yang akan digunakan pada komparasi pada tahap akhir. tahap ini opsional, dan kita hanya lakukan ini agar algoritma dapat berjalan lebih efisien
"""

from sklearn.decomposition import PCA

res = np.array(res)
pca = PCA(n_components=300)
pca.fit(res)

#taking only 300 of our principal components
pca_res = pca.transform(res)

"""###Testing our Model
pada tahap ini kita akan mengambil sebuah foto random dari folder kita dan menggunakan itu sebagai foto yang akan ditargetkan oleh model kita. kemudian kita akan membandingkan vector yang dihasilkan oleh model kita untuk mencari hasil yang paling mirip dengan gambar kita.
"""

from scipy.spatial import distance

def get_closest_images(query_image_idx, num_results=5):
    distances = [ distance.cosine(pca_res[query_image_idx], feat) for feat in pca_res ]
    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[1:num_results+1]
    return idx_closest

def get_concatenated_images(indexes, thumb_height):
    thumbs = []
    for idx in indexes:
        img = tf.keras.utils.load_img(images[idx])
        img = img.resize((int(img.width * thumb_height / img.height), thumb_height))
        thumbs.append(img)
    concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)
    return concat_image

# do a query on a random image
query_image_idx = int(len(images) * random.random())
idx_closest = get_closest_images(query_image_idx)
query_image = get_concatenated_images([query_image_idx], 300)
results_image = get_concatenated_images(idx_closest, 200)

# display the query image
plt.figure(figsize = (5,5))
plt.imshow(query_image)
plt.title("query image (%d)" % query_image_idx)

# display the resulting images
plt.figure(figsize = (16,12))
plt.imshow(results_image)
plt.title("similar images")